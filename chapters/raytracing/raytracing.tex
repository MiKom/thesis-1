\chapter{Implementation details}

\section{Overview}
\emph{Aurora} is a Monte Carlo distribution raytracer for \emph{Autodesk Maya} 3D content creation suite. It features seamless integration with Maya workflow through the native Maya C++ plugin \emph{application programming interface} (API). Scenes can be rendered at any time without the need to export the data to some file format via the render view window within Maya application.

The host code running on the CPU is written in \emph{ISO C++}, the GPU code is written in \emph{CUDA C} and built against NVIDIA CUDA Toolkit 4.2. Aurora is a native x86\_64 Windows dynamically-linked library; solution is provided for Microsoft Visual Studio 2010. All of the source code is licensed under a permissive open source license.\footnote{Refer to: \url{https://github.com/Nadrin/aurora/blob/master/COPYING.txt}}

The design of the system is heavly influenced by the inclusion of device CUDA code and the many limitations of the NVIDIA CUDA C compiler:
\begin{itemize}
\item All GPU kernels are seperated from high level C++ code in a dedicated logical component and placed in the global namespace.
\item Shared device functions are included inline from \emph{cuh} (CUDA header) source files.
\item Kernels are called from C++ code indirectly through host wrapper functions. The role of a wrapper is to setup kernel specific parameters and provide convenient abstraction for CUDA unaware MSVC++ compiler.
\item Classes and types shared between CPU and GPU code don't use inheritance and provide only basic constructors.
\end{itemize}
Special considerations were also made for memory management due to the heavy parallel nature of modern GPUs. When executing kernel by hundreds of threads simulatenously all scene data needs to be loaded into the video RAM for instant access by the running kernel. No loading on demand is utilized as it would be only possible in CPU-based implementation. Data structures used by kernels need to be kept minimal and properly aligned in the format that encourages coalescent access patterns by warps.

In overall, the system can be divided into the following list of high-level components:
\begin{itemize}
\item \texttt{core}: The core of the system performing general and hardware initialization, memory management and Maya scene graph traversal. It also provides common functions for all available renderer implementations.
\item \texttt{data}: Classes responsible for interpreting scene data, rebuilding internal representation and loading it into the video memory.
\item \texttt{kernels}: All CUDA kernels and GPU related code exported to the rest of the system via kernel wrappers.
\item \texttt{kernels/lib}: A library of common device functions and GPU-only data types used by various kernels.
\item \texttt{maya}: The interface to Maya C++/MEL\footnote{MEL is the embedded scripting language for Maya.} API: render command implementation, global renderer registration and user interface related functions.
\item \texttt{render}: Implementations of various renderers. At the time of writing this work two renderer classes are implemented: simple raycaster and monte carlo raytracer. Active renderer class is selected at compile-time. Throughout this work it is assumed that the active renderer is the latter of two.
\item \texttt{util}: Utility functions and shared CPU/GPU data structures.
\end{itemize}

The rest of this chapter focuses on describing implementation details of rendering-related functionality of Aurora. \vfill

\section{Raytracing basics}
The foundation for computational light simulation is the \emph{recursive raytracing} algorithm \parencite{whitted79}. In recursive raytracing virtual rays of light are traced from the virtual camera lens onto the projection plane (the virtual ``film'') and into the scene. At every intersection point with a surface the outgoing illumination is evaluated.

This may seem odd at first since in reality light propagades \emph{from} the light sources to the film in the camera. The correctness of this method follows directly from \emph{Hemholtz reciprocity} \parencite{hapke93} which states that in vaccum or in a passive medium light paths can be reversed without affecting the measurement of flux.

Tracing rays from the camera is often called \emph{backwards raytracing} while tracing from the light sources is called \emph{forward raytracing}. The main drawback of forward raytracing algorithms is that many computed light paths don't hit the camera film at all and thus only small fraction contribute to the final image.

For every reflective or transmittive surface at each intersection point another ray is spawned and the raytracing process continues recursively until either diffuse-only surface is hit or maximum recursion depth is reached. At ray path termination the corresponding framebuffer element is set with the final color value.

\begin{algorithm}
\caption{Simplified recursive raytracing}
\KwData{Ray $r$, set of surface elements $S$, set of light sources $L$.}
\KwResult{Outgoing illumination $I$.}
$I \leftarrow 0$ \\
\If{$r$ interesects with any $s \in S$}{
  $x \leftarrow$ find the nearest intersection point \\
  \For{every light $l \in L$}{
    \If{light $l$ is unoccluded from point $x$}{
      $I_{p} \leftarrow$ compute direct illumination at point $x$ due to $l$ \\
      \If{surface $s(x)$ is reflective or transmittive}{
        $r' \leftarrow$ generate new ray at point $x$ \\
        $I_{s} \leftarrow$ raytrace($r'$, $S$, $L$) \\
      }
      $I \leftarrow I + (I_{p} + I_{s})$
    }
  }
}
\Return{I}
\end{algorithm}

Aurora implements an extension to recursive raytracing called \emph{distribution raytracing}\footnote{Another widely used name is \emph{stochastic raytracing}.}. Distribution raytracing, or Monte Carlo raytracing, uses sampling of multiple ray paths to evaluate the light transport equation using Monte Carlo estimator introduced in chapter \ref{ch:montecarlo}.

\section{Ray intersection testing}
A very important part of every raytracer is testing whether a given ray intersects scene primitives. Proper definition of ray is crucial to understanding ray-primitive intersection tests. 
\begin{df}
  A ray with origin $\vec{p}$ in 3D space and normalized direction vector $\vec{d}$ is defined by
  \begin{equation} \label{eq:ray}
    r(t) := \vec{p} + t\vec{d},
  \end{equation}
  where $t > 0$.
\end{df}

Aurora implements two types of primitives: \emph{triangles} which are renderable primitives used to represent 3D scene surfaces as triangle meshes and \emph{axis-aligned slabs} which are non-renderable primitives used during the traversal of spatial triangle hierarchy. 

\subsection{Ray--triangle intersection}
Compact triangle representation is a key factor in increasing geometry streaming throughput from global memory during rendering on the GPU via CUDA. It is therefore natural to utilize ray/triangle intersection test that does not require extra precomputed data besides triangle vertices. Such test was proposed in \cite{mt97} and it is the algorithm implemented in Aurora.

Consider a ray $r(t)$ and a triangle defined by vertices $V_{0}, V_{1}, V_{2}$. Arbitrary point on this triangle can be expressed in terms of \emph{barycentric coordinates} $\langle u, v \rangle$:
\begin{equation}
  T(u,v) = (1-u-v)V_{0} + uV_{1} + vV_{2},
\end{equation}
where $u, v \ge 0$ and $u+v \le 1$.

The intersection point of ray $r(t)$ and the triangle $T(u,v)$ need to satisfy the equation
\begin{eqnarray}
  r(t) &=& T(u,v) \nonumber \\
  \vec{p} + t\vec{d} &=& (1-u-v)V_{0} + uV_{1} + vV_{2},
\end{eqnarray}
where $t, u$ and $v$ are unknown. Rearranging the terms yields
\begin{equation}
\label{eq:int_triangle}
  \left\lbrack -\vec{d}, V_{1} - V_{0}, V_{2} - V_{0} \right\rbrack
  \left\lbrack 
    \begin{array}{c}
      t\\u\\v
    \end{array}
  \right\rbrack
  = \vec{p} - V_{0}.
\end{equation}
Solving this linear system of equations gives the intersection point in terms of point on the ray ($t$ parameter) and point on the triangle ($u,v$ parameters). 

\subsection{Ray--slab intersection}
The ray/scene intersection method described in section \ref{sec:nmh} needs to be able to test if a ray intersects with a pair of axis-aligned planes (a ``slab'') in 3D space.

Consider a slab $S$ aligned with axis $OX$. The slab is defined by two parallel planes perpendicular to the $OX$ axis and coplanar with the $YZ$ plane. Their position in space can be determined solely by their distance from the origin $S_{\min}, S_{\max} \in \mathbb{R}$.

To find the intersection between plane $S_{\min}$ and ray $r(t)$ one can use equation \ref{eq:ray} in one-dimensional form:
\begin{eqnarray}
  S_{\min} &=& p_{x} + t_{\min} d_{x} \nonumber \\
  t_{\min} &=& \frac{S_{\min} - p_{x}}{d_{x}}
\end{eqnarray}
and similarly for $S_{\max}$:
\begin{equation}
  t_{\max} = \frac{S_{\max} - p_{x}}{d_{x}}.
\end{equation}
Ray $r(t)$ then intersects slab $S$ if and only if $t_{\min} \le t_{\max}$.

Note that the \texttt{IEEE754} standard for floating point arithmetic guarantees that the result of this interesection test will be correct even when $d_{x}=0$. A ray coplanar with the $YZ$ plane intersects slab $S$ at either $+\infty$ or $-\infty$.

Cases for $OY$ and $OZ$ aligned slabs are identical and omitted here for brevity.

\section{The No--Memory Hierarchy}
\label{sec:nmh}
Testing for ray/scene intersection can be very costly. Assuming scene surfaces consist of triangle meshes the naive approach would be to test every triangle and choose the nearest intersection point. For large number of triangles and rays this is higly impractical as the algorithmic complexity is $O(mn)$ where $m$ is the number of rays and $n$ is the number of triangles. Typical rendering scenario consist of tracing millions of rays through a scene with thousands or even millions of triangles. The computational cost of naive intersection testing is clearly prohibitive.

The basic idea of ``accelerating'' ray intersection tests in large scenes is to use some sort of auxiliary spatial data structure that can lower the complexity by testing only a fraction of scene primitives for each ray. Examples of such structures include bounding volume hierarchies, $kd$-trees and sparse voxel grids. Unfortunately in each case the additional data structure significantly increases memory requirements.

The No-Memory Hierarchy or NMH \parencite{eisemann2012} is a method of spatialy sorting triangles to implicitly represent the acceleration strucutre within the geometry data with no need for addtional memory during traversal. The computational complexity of ray/scene intersection when using NMH is $O(m \log n)$ for $m$ rays and $n$ triangles and the additional memory complexity is $O(\log n)$ because of the recursion stack.

\subsection{Representation and traversal}
The NMH is a complete, left-balanced binary tree recursively partitioning the geometry of the scene into two disjoint subsets. Each tree node consists of two triangles, continuously mapped in memory, that implicitly define a bounding primitive.

To find an intersection of a ray with the scene geometry the hierarchy is traversed in breath-first order. At each node bounding primitive is recostructed from the bounding triangles. If the query ray intersects with the bounding primitive both bounding triangles are tested for intersection as well and any existing child nodes are enqueued for visiting. If the query ray misses the bounding primitive the current node is skipped.

The bounding primitive for each node is a slab along one of the coordinate axis. The axis is chosen in a round-robin fashion depending on the depth in the tree, starting from $OX$ at the root node (depth zero). Extents of the bounding slab are defined by minimal and maximal triangle vertex along that axis. The bounding slab with active ray interval approximate an axis-aligned bounding box for the current node.

The hierarchy is stored as a continuous array of triangles in memory and can be addressed like a heap. Index zero is the first triangle in the root node. For any node whose first triangle index is $i$ the indices of corresponding first triangles of its children are respectively $2(i+1)$ and $2(i+2)$. A valid index is always smaller than the total number of triangles in the scene. If a particular node has no valid children indices then it is a leaf node.

\subsection{Construction}
Parallel GPU construction of NMH in Aurora is based on the algorithm described in section 4 of \cite{eisemann2012}.

The NMH construction procedure expects the number of triangles in the scene to be even. If the number of triangles is odd the last triangle is duplicated before construction begins. Let $N$ be the number of triangles after duplication. For performance reasons the algorithm does not operate directly on triangle data; triangle index array $T$ is used instead. A number of other helper buffers are also required: auxiliary index array $I$ of length $N$ which stores the current node index in the hierarchy and two split lists $S_{i}, S_{o}$ of length at most $N/2$ each, carrying information about the starting index and the size of each active partition. Memory complexity of NMH construction is therefore $O(N)$.

At the start $T$ is set to identity permutation $(0, 1, \dots, N-1)$ and $I$ is initialized to zeroes. The input split list $S_{i}$ contains a single active split with starting index $0$ and size $N$ and the bounding axis is set to $OX$.

The algorithm then loops over all $\lfloor \log_{2}(N/2) \rfloor + 1$ levels of the hierarchy and performs the following steps in parallel:
\begin{enumerate}
\item Arrays $T$ and $I$ are sorted by each triangle's minimum vertex position along the bounding axis and then stable sort is applied according to the index arrray $I$. After the first sort the triangles are sorted according to their spatial position. The second sort arranges triangles of the same node together without changing their relative position. For the last level of the hierarchy it is the final step.
\item In each active split the maximum triangle along the current bounding axis is found and swapped to the second position. The first is already the minimum bounding triangle due to sorting.
\item The index array $I$ is now updated. Let $D$ be the number of already created nodes and $i$ be the index of the split in the split list. The first two triangles of each active split are assigned a value of $D+i$. Other triangles in the split are assigned $2(D+i)+1$.
\item For each active split in the input split list $S_{i}$ up to two new splits are emitted into the output split list $S_{o}$. Let $n_{S}$ be the number of active splits and $p_{i}$, $n_{i}$ the position and size of i'th split. The sizes $nL_{i}$ and $nR_{i}$ of the new splits are computed from $n_{i}$ as described in listing \ref{lst:calcpartition}. The starting positions of the new splits are then $pL_{i} = p_{i} + 2(n_{S} - i)$ and $pR_{i} = pL_{i} + nL_{i}$. If either $nL_{i} \le 0$ or $nR_{i} \le 0$ the corresponding split is not created.
\item The bounding axis is incremented and the loop continues.
\end{enumerate}
\begin{lstlisting}[
  label={lst:calcpartition},
  language=C++,
  caption=Partition size calculation resulting in left-balanced object-median split of the triangles. The \texttt{log2i} function returns integer base 2 logarithm.]
void calcPartition(int N, int& L, int& R)
{
  int H = log2i(N/2);
  int s = pow(2, H-1) - 1;
  int S = pow(2, H) - 1;
  int O = max(0, (N/2 - 1) - s - S);
  R = 2 * (s + O);
  L = 2 * (N/2 - 1) - R;
}
\end{lstlisting}
After the loop is finished the scene geometry data is permuted according to the index array $T$ and all temporary helper buffers are freed. The NMH construction is done.

\vfill
\section{Scene geometry}

\section{Lights}

\subsection{Point light}

\subsection{Directional light}

\subsection{Area light}

\section{Shaders}

\subsection{Shading coordinate system}

\subsection{Lambert shader}

\subsection{Reflective shader}

\section{Rendering}

\subsection{Estimating direct lighting integral}

\subsection{Handling specular reflections}

\subsection{Antialiasing and filtering}



